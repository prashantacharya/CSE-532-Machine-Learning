{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files = {\n",
    "    \"100\": \"dataset/features-100.csv\",\n",
    "    \"200\": \"dataset/features-200.csv\",\n",
    "    \"300\": \"dataset/features-300.csv\",\n",
    "    \"400\": \"dataset/features-400.csv\",\n",
    "    \"500\": \"dataset/features-500.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation with various Machine Learning Algorithms\n",
    "\n",
    "Since, most of the time we are doing the same thing for various algorithms, I created a function that takes in the dataset, the algorithm and the required parameters for that particular algorithm. Doing this makes it easy to run the experiments across multiple ML algorithms.\n",
    "\n",
    "I have done something similar for Cross Validation and Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    std_scaler = StandardScaler()\n",
    "    X = std_scaler.fit_transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(feature_files, ml_algorithm, model_params=None):\n",
    "    \"\"\"\n",
    "    This function trains and evaluates a ML algorithm.\n",
    "    I have created this function so that I can easily train and evaluate various\n",
    "    algorithms. \n",
    "    \n",
    "    Since, most of the logic is going to be the same, this function creates an\n",
    "    abstraction layer so that it makes it easier to train and evaluate different\n",
    "    algorithms.\n",
    "\n",
    "    Parameters:\n",
    "        feature_files (dict): A dictionary with window sizes as keys and file names as values.\n",
    "        model_class (class): The machine learning model class (e.g., LogisticRegression).\n",
    "        model_params (dict): A dictionary of parameters to initialize the model (default is None).\n",
    "\n",
    "    Returns:\n",
    "        None: Prints accuracy for each window size.\n",
    "    \"\"\"\n",
    "    for size, file_name in feature_files.items():\n",
    "        print(f\"Training {ml_algorithm.__name__} for window size: {size}\")\n",
    "        \n",
    "        # Load and preprocess the data\n",
    "        df = pd.read_csv(file_name)\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        y = df['activity_id']\n",
    "        X = df.drop('activity_id', axis=1)\n",
    "        X = scale(X)\n",
    "\n",
    "        if ml_algorithm.__name__ == 'XGBClassifier':\n",
    "            y = y - 1\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Initialize the model\n",
    "        if model_params:\n",
    "            model = ml_algorithm(**model_params)\n",
    "        else:\n",
    "            model = ml_algorithm()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, average='macro', zero_division=0)  \n",
    "        recall = recall_score(y_test, predictions, average='macro')\n",
    "        f1 = f1_score(y_test, predictions, average='macro')\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression for window size: 100\n",
      "Accuracy: 0.42396187882913544\n",
      "Precision: 0.42047817806857263\n",
      "Recall: 0.41226071937400655\n",
      "F1 Score: 0.401622781260607\n",
      "==================================================\n",
      "Training LogisticRegression for window size: 200\n",
      "Accuracy: 0.41922345913657344\n",
      "Precision: 0.44050032386698024\n",
      "Recall: 0.41659175283233124\n",
      "F1 Score: 0.40967965101489323\n",
      "==================================================\n",
      "Training LogisticRegression for window size: 300\n",
      "Accuracy: 0.4346060113728676\n",
      "Precision: 0.4476299500032407\n",
      "Recall: 0.4290840599574533\n",
      "F1 Score: 0.4252802563959834\n",
      "==================================================\n",
      "Training LogisticRegression for window size: 400\n",
      "Accuracy: 0.43844492440604754\n",
      "Precision: 0.46283326479492326\n",
      "Recall: 0.4280027756709098\n",
      "F1 Score: 0.4264033577847743\n",
      "==================================================\n",
      "Training LogisticRegression for window size: 500\n",
      "Accuracy: 0.4383838383838384\n",
      "Precision: 0.44129030503393624\n",
      "Recall: 0.4349611794252095\n",
      "F1 Score: 0.42202138195429323\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, LogisticRegression, {'solver': 'lbfgs', 'max_iter': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier for window size: 100\n",
      "Accuracy: 0.4157930565010211\n",
      "Precision: 0.3961468952354379\n",
      "Recall: 0.4067169587887655\n",
      "F1 Score: 0.3660533635449512\n",
      "==================================================\n",
      "Training DecisionTreeClassifier for window size: 200\n",
      "Accuracy: 0.4270974748846049\n",
      "Precision: 0.42985348353023106\n",
      "Recall: 0.42026007237438345\n",
      "F1 Score: 0.3781270885837888\n",
      "==================================================\n",
      "Training DecisionTreeClassifier for window size: 300\n",
      "Accuracy: 0.43826157595450854\n",
      "Precision: 0.44521390490692664\n",
      "Recall: 0.4265978776488403\n",
      "F1 Score: 0.39703488424872574\n",
      "==================================================\n",
      "Training DecisionTreeClassifier for window size: 400\n",
      "Accuracy: 0.4400647948164147\n",
      "Precision: 0.43613582618268854\n",
      "Recall: 0.4171843857529961\n",
      "F1 Score: 0.3936712843458931\n",
      "==================================================\n",
      "Training DecisionTreeClassifier for window size: 500\n",
      "Accuracy: 0.4734006734006734\n",
      "Precision: 0.4573637565694791\n",
      "Recall: 0.4633338795297559\n",
      "F1 Score: 0.4258439080527626\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, DecisionTreeClassifier, {'max_depth': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier for window size: 100\n",
      "Accuracy: 0.8183798502382573\n",
      "Precision: 0.8169757017384732\n",
      "Recall: 0.8091634592685303\n",
      "F1 Score: 0.8100983159339668\n",
      "==================================================\n",
      "Training RandomForestClassifier for window size: 200\n",
      "Accuracy: 0.8259571001900624\n",
      "Precision: 0.8280500587906179\n",
      "Recall: 0.820999839229636\n",
      "F1 Score: 0.8217680224319058\n",
      "==================================================\n",
      "Training RandomForestClassifier for window size: 300\n",
      "Accuracy: 0.838748984565394\n",
      "Precision: 0.8387837644644031\n",
      "Recall: 0.8313706036249803\n",
      "F1 Score: 0.8335830935528374\n",
      "==================================================\n",
      "Training RandomForestClassifier for window size: 400\n",
      "Accuracy: 0.8336933045356372\n",
      "Precision: 0.8329544536414812\n",
      "Recall: 0.8262166829272612\n",
      "F1 Score: 0.8278547526459662\n",
      "==================================================\n",
      "Training RandomForestClassifier for window size: 500\n",
      "Accuracy: 0.8430976430976431\n",
      "Precision: 0.8425091678422217\n",
      "Recall: 0.837902255994947\n",
      "F1 Score: 0.8388178744083652\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, RandomForestClassifier, {'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC for window size: 100\n",
      "Accuracy: 0.4893124574540504\n",
      "Precision: 0.5337113332113355\n",
      "Recall: 0.47355152180437404\n",
      "F1 Score: 0.46210741560285556\n",
      "==================================================\n",
      "Training SVC for window size: 200\n",
      "Accuracy: 0.4833016562584849\n",
      "Precision: 0.5455315063273193\n",
      "Recall: 0.4806186176230502\n",
      "F1 Score: 0.46850618668025495\n",
      "==================================================\n",
      "Training SVC for window size: 300\n",
      "Accuracy: 0.48578391551584077\n",
      "Precision: 0.5588467992392718\n",
      "Recall: 0.476164524026202\n",
      "F1 Score: 0.47096939053205494\n",
      "==================================================\n",
      "Training SVC for window size: 400\n",
      "Accuracy: 0.4789416846652268\n",
      "Precision: 0.5272813581180716\n",
      "Recall: 0.46769480060984664\n",
      "F1 Score: 0.4604262889434102\n",
      "==================================================\n",
      "Training SVC for window size: 500\n",
      "Accuracy: 0.4734006734006734\n",
      "Precision: 0.5201435907618056\n",
      "Recall: 0.4683085405422709\n",
      "F1 Score: 0.4557141624603081\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, SVC, {\"C\": 100.0, \"gamma\": 0.001, \"kernel\":\"rbf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GaussianNB for window size: 100\n",
      "Accuracy: 0.33356024506466986\n",
      "Precision: 0.33507917428053374\n",
      "Recall: 0.3271286799571434\n",
      "F1 Score: 0.299945403950775\n",
      "==================================================\n",
      "Training GaussianNB for window size: 200\n",
      "Accuracy: 0.33016562584849307\n",
      "Precision: 0.37522149929159826\n",
      "Recall: 0.3327537767206723\n",
      "F1 Score: 0.3145249457568287\n",
      "==================================================\n",
      "Training GaussianNB for window size: 300\n",
      "Accuracy: 0.335093419983753\n",
      "Precision: 0.3882908057509773\n",
      "Recall: 0.3403627762103839\n",
      "F1 Score: 0.32590835521594214\n",
      "==================================================\n",
      "Training GaussianNB for window size: 400\n",
      "Accuracy: 0.34719222462203025\n",
      "Precision: 0.39858741306818785\n",
      "Recall: 0.3383484285495345\n",
      "F1 Score: 0.32854084201467576\n",
      "==================================================\n",
      "Training GaussianNB for window size: 500\n",
      "Accuracy: 0.3367003367003367\n",
      "Precision: 0.3999539861664056\n",
      "Recall: 0.34009945004069064\n",
      "F1 Score: 0.3272048074843308\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsClassifier for window size: 100\n",
      "Accuracy: 0.7257998638529612\n",
      "Precision: 0.7242067013725346\n",
      "Recall: 0.7185555696195433\n",
      "F1 Score: 0.71716518888342\n",
      "==================================================\n",
      "Training KNeighborsClassifier for window size: 200\n",
      "Accuracy: 0.7181645397773554\n",
      "Precision: 0.7184270747225522\n",
      "Recall: 0.715999858514118\n",
      "F1 Score: 0.7133891200687837\n",
      "==================================================\n",
      "Training KNeighborsClassifier for window size: 300\n",
      "Accuracy: 0.7136474411047928\n",
      "Precision: 0.7080458067771469\n",
      "Recall: 0.706348632892544\n",
      "F1 Score: 0.704675737900267\n",
      "==================================================\n",
      "Training KNeighborsClassifier for window size: 400\n",
      "Accuracy: 0.7073434125269978\n",
      "Precision: 0.7078440903265667\n",
      "Recall: 0.7025817515915537\n",
      "F1 Score: 0.7014501766811445\n",
      "==================================================\n",
      "Training KNeighborsClassifier for window size: 500\n",
      "Accuracy: 0.7117845117845117\n",
      "Precision: 0.715102049009135\n",
      "Recall: 0.7105185914175001\n",
      "F1 Score: 0.7090464082478481\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoostClassifier for window size: 100\n",
      "Accuracy: 0.34758339006126615\n",
      "Precision: 0.2945739504209159\n",
      "Recall: 0.32322111431643324\n",
      "F1 Score: 0.28609911501317814\n",
      "==================================================\n",
      "Training AdaBoostClassifier for window size: 200\n",
      "Accuracy: 0.2777626934564214\n",
      "Precision: 0.3052671684490424\n",
      "Recall: 0.26548488629873757\n",
      "F1 Score: 0.23322926860444743\n",
      "==================================================\n",
      "Training AdaBoostClassifier for window size: 300\n",
      "Accuracy: 0.28107229894394803\n",
      "Precision: 0.26338666808185673\n",
      "Recall: 0.26017435251616544\n",
      "F1 Score: 0.23051255630465028\n",
      "==================================================\n",
      "Training AdaBoostClassifier for window size: 400\n",
      "Accuracy: 0.23704103671706264\n",
      "Precision: 0.16552623155857746\n",
      "Recall: 0.22666942222129766\n",
      "F1 Score: 0.16789487599535236\n",
      "==================================================\n",
      "Training AdaBoostClassifier for window size: 500\n",
      "Accuracy: 0.26936026936026936\n",
      "Precision: 0.19498101555768474\n",
      "Recall: 0.25514781738189735\n",
      "F1 Score: 0.20399081669334446\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, AdaBoostClassifier, {\"n_estimators\" : 100, \"algorithm\": 'SAMME' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GradientBoostingClassifier for window size: 100\n",
      "Accuracy: 0.7417290673927842\n",
      "Precision: 0.7363616801713418\n",
      "Recall: 0.7314146116234803\n",
      "F1 Score: 0.7307494480542877\n",
      "==================================================\n",
      "Training GradientBoostingClassifier for window size: 200\n",
      "Accuracy: 0.7664947054032039\n",
      "Precision: 0.7657759243314246\n",
      "Recall: 0.7618773672454686\n",
      "F1 Score: 0.7617186902094669\n",
      "==================================================\n",
      "Training GradientBoostingClassifier for window size: 300\n",
      "Accuracy: 0.7802599512591389\n",
      "Precision: 0.7754324203024848\n",
      "Recall: 0.7710754199284697\n",
      "F1 Score: 0.7724640600824194\n",
      "==================================================\n",
      "Training GradientBoostingClassifier for window size: 400\n",
      "Accuracy: 0.7818574514038877\n",
      "Precision: 0.7786754946723472\n",
      "Recall: 0.773806939174359\n",
      "F1 Score: 0.7747413923718866\n",
      "==================================================\n",
      "Training GradientBoostingClassifier for window size: 500\n",
      "Accuracy: 0.8013468013468014\n",
      "Precision: 0.7984127445816974\n",
      "Recall: 0.7949903132738547\n",
      "F1 Score: 0.7955991866812389\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(feature_files, GradientBoostingClassifier, {\"n_estimators\" : 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier for window size: 100\n",
      "Accuracy: 0.6887678692988427\n",
      "Precision: 0.6861091475560914\n",
      "Recall: 0.6775500136019608\n",
      "F1 Score: 0.6732300051666685\n",
      "==================================================\n",
      "Training XGBClassifier for window size: 200\n",
      "Accuracy: 0.7159923975020364\n",
      "Precision: 0.7184935362450948\n",
      "Recall: 0.7110557075352782\n",
      "F1 Score: 0.7084631644353869\n",
      "==================================================\n",
      "Training XGBClassifier for window size: 300\n",
      "Accuracy: 0.7335499593826158\n",
      "Precision: 0.7315562415150207\n",
      "Recall: 0.7242210968265692\n",
      "F1 Score: 0.7247711258733005\n",
      "==================================================\n",
      "Training XGBClassifier for window size: 400\n",
      "Accuracy: 0.740280777537797\n",
      "Precision: 0.7425207189322992\n",
      "Recall: 0.7311302511807669\n",
      "F1 Score: 0.7327455926707337\n",
      "==================================================\n",
      "Training XGBClassifier for window size: 500\n",
      "Accuracy: 0.7569023569023569\n",
      "Precision: 0.7561156777636734\n",
      "Recall: 0.7516760809873374\n",
      "F1 Score: 0.7508475363421392\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(feature_files, XGBClassifier, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLPClassifier for window size: 100\n",
      "Accuracy: 0.7253914227365554\n",
      "Precision: 0.7203229845020502\n",
      "Recall: 0.7167726400668906\n",
      "F1 Score: 0.7161892970386828\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 200\n",
      "Accuracy: 0.7320119467825142\n",
      "Precision: 0.7316352105603557\n",
      "Recall: 0.7282649121747075\n",
      "F1 Score: 0.7283910168708003\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 300\n",
      "Accuracy: 0.7404549147034931\n",
      "Precision: 0.7403426338313215\n",
      "Recall: 0.7339524593747571\n",
      "F1 Score: 0.7351961230241761\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 400\n",
      "Accuracy: 0.7294816414686826\n",
      "Precision: 0.7262401519247679\n",
      "Recall: 0.7234027004898053\n",
      "F1 Score: 0.7218627787812824\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 500\n",
      "Accuracy: 0.7494949494949495\n",
      "Precision: 0.7434514810729741\n",
      "Recall: 0.7447386603084059\n",
      "F1 Score: 0.7416176515010905\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "ann_params = {\n",
    "    'max_iter': 3000,\n",
    "    'activation': 'logistic',\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(feature_files, MLPClassifier, ann_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLPClassifier for window size: 100\n",
      "Accuracy: 0.7225323349217154\n",
      "Precision: 0.7205783740414644\n",
      "Recall: 0.7134481053321561\n",
      "F1 Score: 0.7130062300934281\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 200\n",
      "Accuracy: 0.7241379310344828\n",
      "Precision: 0.7230290501171068\n",
      "Recall: 0.7177800179503839\n",
      "F1 Score: 0.7171437444030067\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 300\n",
      "Accuracy: 0.735174654752234\n",
      "Precision: 0.7330945937123787\n",
      "Recall: 0.7295067702029209\n",
      "F1 Score: 0.7298072427352265\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 400\n",
      "Accuracy: 0.7230021598272138\n",
      "Precision: 0.7214571437207993\n",
      "Recall: 0.7178113367413078\n",
      "F1 Score: 0.7174041967177516\n",
      "==================================================\n",
      "Training MLPClassifier for window size: 500\n",
      "Accuracy: 0.7548821548821549\n",
      "Precision: 0.751159873775539\n",
      "Recall: 0.7517941036390824\n",
      "F1 Score: 0.7498503971120871\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "ann_params = {\n",
    "    'max_iter': 1000,\n",
    "    'activation': 'relu',\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(feature_files, MLPClassifier, ann_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut, LeavePOut\n",
    "\n",
    "def cross_validate_model(ml_algorithm, feature_files, cv_function=KFold, params=None, cv_params=None):\n",
    "    \"\"\"\n",
    "    This function performs cross-validation on a given ML model with given cross validation function.\n",
    "\n",
    "    Parameters:\n",
    "        ml_algorithm (class): The machine learning model class (e.g., LogisticRegression).\n",
    "        feature_files (list): List of feature files.\n",
    "        cv_function (class): The cross-validation function (e.g., KFold).\n",
    "        params (dict): Dictionary of parameters for the ML model.\n",
    "        cv_params (dict): Dictionary of parameters for the cross-validation function.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean accuracy from cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    for size, feature_file in feature_files.items():\n",
    "        # Load data\n",
    "        df = pd.read_csv(feature_file)\n",
    "        X = df.drop('activity_id', axis=1)\n",
    "        y = df['activity_id']\n",
    "\n",
    "        # fill na\n",
    "        X.fillna(X.mean(), inplace=True)\n",
    "        X = scale(X)\n",
    "\n",
    "        cv = cv_function(**cv_params)\n",
    "\n",
    "        # Perform cross-validation\n",
    "        scores = cross_val_score(ml_algorithm(**params), X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "        # Return mean accuracy\n",
    "        print(f\"{cv_function.__name__} Cross-Validation for window size {size} and Algorithm {ml_algorithm.__name__}:\")\n",
    "        print(f\"Average Accuracy: {scores.mean()}\")\n",
    "        print(f\"Max Accuracy: {scores.max()}\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm LogisticRegression:\n",
      "Average Accuracy: 0.28417036793844497\n",
      "Max Accuracy: 0.35566448801742917\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm LogisticRegression:\n",
      "Average Accuracy: 0.2815203640564981\n",
      "Max Accuracy: 0.3702497285559175\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm LogisticRegression:\n",
      "Average Accuracy: 0.2870836718115354\n",
      "Max Accuracy: 0.3793663688058489\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm LogisticRegression:\n",
      "Average Accuracy: 0.28961450002918687\n",
      "Max Accuracy: 0.37688984881209503\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm LogisticRegression:\n",
      "Average Accuracy: 0.2921529967023758\n",
      "Max Accuracy: 0.3835800807537012\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"penalty\": \"l2\",\n",
    "    \"C\": 0.1,\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=LogisticRegression,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm DecisionTreeClassifier:\n",
      "Average Accuracy: 0.33936894947348817\n",
      "Max Accuracy: 0.3954248366013072\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm DecisionTreeClassifier:\n",
      "Average Accuracy: 0.3376762322322818\n",
      "Max Accuracy: 0.3997827267789245\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm DecisionTreeClassifier:\n",
      "Average Accuracy: 0.3323314378554021\n",
      "Max Accuracy: 0.3980503655564582\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm DecisionTreeClassifier:\n",
      "Average Accuracy: 0.3484999124394373\n",
      "Max Accuracy: 0.43783783783783786\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm DecisionTreeClassifier:\n",
      "Average Accuracy: 0.31856029138083025\n",
      "Max Accuracy: 0.39703903095558546\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_split\": 2,\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=DecisionTreeClassifier,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm RandomForestClassifier:\n",
      "Average Accuracy: 0.38275102808162015\n",
      "Max Accuracy: 0.48366013071895425\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm RandomForestClassifier:\n",
      "Average Accuracy: 0.3914395884312036\n",
      "Max Accuracy: 0.510314875135722\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm RandomForestClassifier:\n",
      "Average Accuracy: 0.40243704305442723\n",
      "Max Accuracy: 0.5215272136474411\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm RandomForestClassifier:\n",
      "Average Accuracy: 0.38922479715136304\n",
      "Max Accuracy: 0.4956803455723542\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm RandomForestClassifier:\n",
      "Average Accuracy: 0.38145530794150617\n",
      "Max Accuracy: 0.5141318977119784\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_split\": 2,\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=RandomForestClassifier,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm GaussianNB:\n",
      "Average Accuracy: 0.29525483908661626\n",
      "Max Accuracy: 0.36437908496732024\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm GaussianNB:\n",
      "Average Accuracy: 0.29450562380238743\n",
      "Max Accuracy: 0.34364820846905536\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm GaussianNB:\n",
      "Average Accuracy: 0.29228269699431353\n",
      "Max Accuracy: 0.3411860276198213\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm GaussianNB:\n",
      "Average Accuracy: 0.2950208394139279\n",
      "Max Accuracy: 0.3617710583153348\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm GaussianNB:\n",
      "Average Accuracy: 0.2914960112895561\n",
      "Max Accuracy: 0.3463611859838275\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"var_smoothing\": 1e-9,\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=GaussianNB,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm SVC:\n",
      "Average Accuracy: 0.3401871514858174\n",
      "Max Accuracy: 0.477124183006536\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm SVC:\n",
      "Average Accuracy: 0.3374484610108395\n",
      "Max Accuracy: 0.48805646036916395\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm SVC:\n",
      "Average Accuracy: 0.33785540211210396\n",
      "Max Accuracy: 0.5004061738424046\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm SVC:\n",
      "Average Accuracy: 0.33831801996380834\n",
      "Max Accuracy: 0.5075593952483801\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm SVC:\n",
      "Average Accuracy: 0.3377871817103387\n",
      "Max Accuracy: 0.5087483176312247\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"C\": 1.0,\n",
    "    \"kernel\": \"rbf\",\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=SVC,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm KNeighborsClassifier:\n",
      "Average Accuracy: 0.2946011998289348\n",
      "Max Accuracy: 0.4463507625272331\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm KNeighborsClassifier:\n",
      "Average Accuracy: 0.29905571076475573\n",
      "Max Accuracy: 0.4717698154180239\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm KNeighborsClassifier:\n",
      "Average Accuracy: 0.3022745735174655\n",
      "Max Accuracy: 0.4841592201462226\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm KNeighborsClassifier:\n",
      "Average Accuracy: 0.3049413344229759\n",
      "Max Accuracy: 0.4794816414686825\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm KNeighborsClassifier:\n",
      "Average Accuracy: 0.3017010516845454\n",
      "Max Accuracy: 0.4939434724091521\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"n_neighbors\": 5,\n",
    "    \"algorithm\": \"auto\",\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=KNeighborsClassifier,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm AdaBoostClassifier:\n",
      "Average Accuracy: 0.25734493361733474\n",
      "Max Accuracy: 0.33306100217864926\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm AdaBoostClassifier:\n",
      "Average Accuracy: 0.26164865198008214\n",
      "Max Accuracy: 0.329712112982075\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm AdaBoostClassifier:\n",
      "Average Accuracy: 0.22794476035743294\n",
      "Max Accuracy: 0.330625507717303\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm AdaBoostClassifier:\n",
      "Average Accuracy: 0.2234190648531901\n",
      "Max Accuracy: 0.36609071274298055\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm AdaBoostClassifier:\n",
      "Average Accuracy: 0.24757920283835114\n",
      "Max Accuracy: 0.33423180592991913\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"n_estimators\": 50,\n",
    "    \"learning_rate\": 1.0,\n",
    "    \"algorithm\": \"SAMME\"\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=AdaBoostClassifier,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Cross-Validation for window size 100 and Algorithm MLPClassifier:\n",
      "Average Accuracy: 0.3294024522111837\n",
      "Max Accuracy: 0.48366013071895425\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 200 and Algorithm MLPClassifier:\n",
      "Average Accuracy: 0.3339178301458927\n",
      "Max Accuracy: 0.46742671009771986\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 300 and Algorithm MLPClassifier:\n",
      "Average Accuracy: 0.3627944760357433\n",
      "Max Accuracy: 0.5385865150284321\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 400 and Algorithm MLPClassifier:\n",
      "Average Accuracy: 0.35722117798143715\n",
      "Max Accuracy: 0.5669546436285097\n",
      "======================================================================\n",
      "KFold Cross-Validation for window size 500 and Algorithm MLPClassifier:\n",
      "Average Accuracy: 0.3616287506393908\n",
      "Max Accuracy: 0.5356662180349933\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ml_algorithm_params = {\n",
    "    \"hidden_layer_sizes\": 100,\n",
    "    \"activation\": \"relu\",\n",
    "    \"solver\": \"adam\",\n",
    "    \"max_iter\": 2000,\n",
    "}\n",
    "\n",
    "cv_params = {\n",
    "    \"n_splits\": 10,\n",
    "}\n",
    "\n",
    "cross_validate_model(feature_files=feature_files,\n",
    "    cv_function=KFold, \n",
    "    ml_algorithm=MLPClassifier,\n",
    "    params=ml_algorithm_params,\n",
    "    cv_params=cv_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    ml_algorithm,\n",
    "    param_grid,\n",
    "    feature_files,\n",
    "    search_function=GridSearchCV,\n",
    "    cv_function=KFold,\n",
    "    search_params=None,\n",
    "    cv_params=None,\n",
    "    subset_rows=None\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs hyperparameter tuning for a given ML model using GridSearchCV or RandomizedSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "        ml_algorithm (class): The machine learning model class (e.g., LogisticRegression).\n",
    "        param_grid (dict): Dictionary with parameters names (`str`) as keys and lists of parameter settings to try as values.\n",
    "        feature_files (dict): Dictionary with feature file names and corresponding window sizes.\n",
    "        search_function (class): Hyperparameter search function (e.g., GridSearchCV or RandomizedSearchCV).\n",
    "        cv_function (class): The cross-validation function (e.g., KFold).\n",
    "        search_params (dict): Additional parameters for the hyperparameter search function.\n",
    "        cv_params (dict): Dictionary of parameters for the cross-validation function.\n",
    "        subset_rows (int, optional): Number of rows to sample from the dataset. Default is None (use entire dataset).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with best parameters for each feature file.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for size, feature_file in feature_files.items():\n",
    "        # Load data\n",
    "        df = pd.read_csv(feature_file)\n",
    "        \n",
    "        # Sample the dataset if subset_rows is specified\n",
    "        if subset_rows and subset_rows < len(df):\n",
    "            df = df.sample(n=subset_rows, random_state=42)\n",
    "        \n",
    "        X = df.drop('activity_id', axis=1)\n",
    "        y = df['activity_id']\n",
    "\n",
    "        # Fill missing values and scale data\n",
    "        X.fillna(X.mean(), inplace=True)\n",
    "        X = scale(X)\n",
    "\n",
    "        # Create cross-validation object\n",
    "        cv = cv_function(**cv_params)\n",
    "\n",
    "        # Adjust parameter name based on the search function\n",
    "        param_key = 'param_grid' if search_function.__name__ == 'GridSearchCV' else 'param_distributions'\n",
    "\n",
    "        # Set up the search function\n",
    "        search = search_function(\n",
    "            estimator=ml_algorithm(),\n",
    "            **{param_key: param_grid},\n",
    "            cv=cv,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            **(search_params if search_params else {})\n",
    "        )\n",
    "\n",
    "        # Perform the search\n",
    "        search.fit(X, y)\n",
    "\n",
    "        # Save the results\n",
    "        results[size] = {\n",
    "            'best_params': search.best_params_,\n",
    "            'best_score': search.best_score_\n",
    "        }\n",
    "\n",
    "        print(f\"{search_function.__name__} Hyperparameter Tuning for window size {size} and Algorithm {ml_algorithm.__name__}:\")\n",
    "        if subset_rows:\n",
    "            print(f\"Randomly sampled {subset_rows} rows from the dataset.\")\n",
    "        print(f\"Best Parameters: {search.best_params_}\")\n",
    "        print(f\"Best Accuracy: {search.best_score_}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.44275114 0.46915099 0.41069182        nan        nan\n",
      "        nan 0.44584842        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV Hyperparameter Tuning for window size 500 and Algorithm LogisticRegression:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 5000, 'C': 10}\n",
      "Best Accuracy: 0.4691509887736303\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid_logreg = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],  # solvers that support l1 and elasticnet\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "results_logreg = tune_hyperparameters(\n",
    "    ml_algorithm=LogisticRegression,\n",
    "    param_grid=param_grid_logreg,\n",
    "    feature_files={\n",
    "        '500': 'dataset/features-500.csv',\n",
    "    },\n",
    "    search_function=RandomizedSearchCV,\n",
    "    cv_function=KFold,\n",
    "    search_params={'verbose': 1},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42},\n",
    "    subset_rows=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 100 and Algorithm SVC:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'C': 100}\n",
      "Best Accuracy: 0.5589000000000001\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 200 and Algorithm SVC:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'C': 100}\n",
      "Best Accuracy: 0.6733\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 300 and Algorithm SVC:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'auto', 'degree': 3, 'C': 100}\n",
      "Best Accuracy: 0.6958\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 400 and Algorithm SVC:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'auto', 'degree': 2, 'C': 100}\n",
      "Best Accuracy: 0.7105982639703249\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 500 and Algorithm SVC:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'C': 100}\n",
      "Best Accuracy: 0.6202848793414831\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for SVC\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],  # Only relevant for 'poly' kernel\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "results_svc = tune_hyperparameters(\n",
    "    ml_algorithm=SVC,\n",
    "    param_grid=param_grid_svc,\n",
    "    feature_files=feature_files,\n",
    "    search_function=RandomizedSearchCV,\n",
    "    cv_function=StratifiedKFold,\n",
    "    search_params={'verbose': 1},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42},\n",
    "    subset_rows=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "GridSearchCV Hyperparameter Tuning for window size 100 and Algorithm RandomForestClassifier:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Accuracy: 0.8181966338460352\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "GridSearchCV Hyperparameter Tuning for window size 200 and Algorithm RandomForestClassifier:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Accuracy: 0.8323556431675228\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "GridSearchCV Hyperparameter Tuning for window size 300 and Algorithm RandomForestClassifier:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Accuracy: 0.8363119415109667\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "GridSearchCV Hyperparameter Tuning for window size 400 and Algorithm RandomForestClassifier:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Accuracy: 0.8400137454157639\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "GridSearchCV Hyperparameter Tuning for window size 500 and Algorithm RandomForestClassifier:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Accuracy: 0.8433456759871856\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Tuning parameters\n",
    "results = tune_hyperparameters(\n",
    "    ml_algorithm=RandomForestClassifier,\n",
    "    param_grid=param_grid,\n",
    "    feature_files=feature_files,\n",
    "    search_function=GridSearchCV,\n",
    "    cv_function=KFold,\n",
    "    search_params={'verbose': 1},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Hyperparameter Tuning for window size 100 and Algorithm MLPClassifier:\n",
      "Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (150,), 'max_iter': 3000, 'solver': 'adam'}\n",
      "Best Accuracy: 0.7414831610732182\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Hyperparameter Tuning for window size 200 and Algorithm MLPClassifier:\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (150,), 'max_iter': 3000, 'solver': 'adam'}\n",
      "Best Accuracy: 0.7526328744766351\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Hyperparameter Tuning for window size 300 and Algorithm MLPClassifier:\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (150,), 'max_iter': 3000, 'solver': 'adam'}\n",
      "Best Accuracy: 0.7558895207148659\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Hyperparameter Tuning for window size 400 and Algorithm MLPClassifier:\n",
      "Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (150,), 'max_iter': 3000, 'solver': 'adam'}\n",
      "Best Accuracy: 0.7464666813688939\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Hyperparameter Tuning for window size 500 and Algorithm MLPClassifier:\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (150,), 'max_iter': 3000, 'solver': 'adam'}\n",
      "Best Accuracy: 0.7621208491019812\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (150,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [3000],\n",
    "}\n",
    "\n",
    "results = tune_hyperparameters(\n",
    "    ml_algorithm=MLPClassifier,\n",
    "    param_grid=param_grid,\n",
    "    feature_files=feature_files,\n",
    "    search_function=GridSearchCV,\n",
    "    cv_function=KFold,\n",
    "    search_params={'verbose': 1},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 100 and Algorithm DecisionTreeClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best Accuracy: 0.6517000000000001\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 200 and Algorithm DecisionTreeClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'log_loss'}\n",
      "Best Accuracy: 0.6940999999999999\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 300 and Algorithm DecisionTreeClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best Accuracy: 0.7259\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 400 and Algorithm DecisionTreeClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Best Accuracy: 0.7307973741355147\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 500 and Algorithm DecisionTreeClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best Accuracy: 0.7288530407398331\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "results_dt = tune_hyperparameters(\n",
    "    ml_algorithm=DecisionTreeClassifier,\n",
    "    param_grid=param_grid_dt,\n",
    "    feature_files=feature_files,\n",
    "    search_function=RandomizedSearchCV,\n",
    "    cv_function=StratifiedKFold,\n",
    "    search_params={'verbose': 1, 'n_iter': 20},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42},\n",
    "    subset_rows=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV Hyperparameter Tuning for window size 100 and Algorithm RandomForestClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best Accuracy: 0.7725000000000001\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 200 and Algorithm RandomForestClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best Accuracy: 0.8183\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 300 and Algorithm RandomForestClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'log_loss', 'bootstrap': False}\n",
      "Best Accuracy: 0.8393\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 400 and Algorithm RandomForestClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 20, 'criterion': 'log_loss', 'bootstrap': False}\n",
      "Best Accuracy: 0.8524335103434837\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 500 and Algorithm RandomForestClassifier:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best Accuracy: 0.8521007922894714\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomForestClassifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "results_rf = tune_hyperparameters(\n",
    "    ml_algorithm=RandomForestClassifier,\n",
    "    param_grid=param_grid_rf,\n",
    "    feature_files=feature_files,\n",
    "    search_function=RandomizedSearchCV,\n",
    "    cv_function=StratifiedKFold,\n",
    "    search_params={'verbose': 1, 'n_iter': 30},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42},\n",
    "    subset_rows=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV Hyperparameter Tuning for window size 100 and Algorithm GaussianNB:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'var_smoothing': 1e-05}\n",
      "Best Accuracy: 0.33190000000000003\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV Hyperparameter Tuning for window size 200 and Algorithm GaussianNB:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'var_smoothing': 1e-09}\n",
      "Best Accuracy: 0.33270000000000005\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 300 and Algorithm GaussianNB:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'var_smoothing': 1e-06}\n",
      "Best Accuracy: 0.332\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "RandomizedSearchCV Hyperparameter Tuning for window size 400 and Algorithm GaussianNB:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'var_smoothing': 1e-08}\n",
      "Best Accuracy: 0.3462236862217959\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/acharyp/Projects/ml-projects/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV Hyperparameter Tuning for window size 500 and Algorithm GaussianNB:\n",
      "Randomly sampled 10000 rows from the dataset.\n",
      "Best Parameters: {'var_smoothing': 1e-09}\n",
      "Best Accuracy: 0.3477900296768221\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GaussianNB\n",
    "param_grid_gnb = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5],\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "results_gnb = tune_hyperparameters(\n",
    "    ml_algorithm=GaussianNB,\n",
    "    param_grid=param_grid_gnb,\n",
    "    feature_files=feature_files,\n",
    "    search_function=RandomizedSearchCV,\n",
    "    cv_function=StratifiedKFold,\n",
    "    search_params={'verbose': 1, 'n_iter': 10},\n",
    "    cv_params={'n_splits': 5, 'shuffle': True, 'random_state': 42},\n",
    "    subset_rows=10000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
